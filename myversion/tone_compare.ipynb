{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCYUNbitr4Ee",
    "outputId": "3bc6c436-fa21-4da1-a3cb-31a826cc177d"
   },
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install audioread filetype moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hH_fJ6hKKkMn"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import soundfile as sf\n",
    "import base64\n",
    "\n",
    "import threading\n",
    "\n",
    "from IPython.display import Audio, display, HTML\n",
    "from matplotlib import rc\n",
    "from IPython.display import Video\n",
    "\n",
    "rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A49KoNFus452"
   },
   "outputs": [],
   "source": [
    "# 오디오 파일 경로\n",
    "import filetype\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "file1 = 'C:/Users/juyon/Desktop/MyVersion/music_samples/저스디스mr제거.mp3'\n",
    "file2 = 'C:/Users/juyon/Desktop/MyVersion/music_samples/일반인_무반주.mp3'\n",
    "file3 = 'C:/Users/juyon/Desktop/MyVersion/music_samples/시은이.mp4'\n",
    "\n",
    "def convert_to_mp3(input_file, output_file):\n",
    "    try:\n",
    "        audio_clip = AudioFileClip(input_file)\n",
    "        audio_clip.write_audiofile(output_file, codec='mp3')\n",
    "        print(f\"Converted {input_file} to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {input_file} to MP3: {e}\")\n",
    "\n",
    "# 파일 형식 확인\n",
    "def check_and_convert(file_path):\n",
    "    kind = filetype.guess(file_path)\n",
    "    if kind is None:\n",
    "        print(f\"Cannot guess file type for {file_path}!\")\n",
    "        return file_path #변환하지 않고 원본파일 사용\n",
    "    print(f\"File extension: {kind.extension}\")\n",
    "    print(f\"File MIME type: {kind.mime}\")\n",
    "    \n",
    "    if kind.extension != 'mp3':\n",
    "        output_file = os.path.splitext(file_path)[0] + \".mp3\"\n",
    "        convert_to_mp3(file_path, output_file)\n",
    "        return output_file # 변환된 파일 경로 반환\n",
    "    else:\n",
    "        return file_path#이미 MP3인 경우 원본 파일 반환\n",
    "    \n",
    "file1 = check_and_convert(file1)\n",
    "file2 = check_and_convert(file2)\n",
    "file2 = check_and_convert(file2)\n",
    "    \n",
    "# 파일 확장자 문제 있었음. 음원 파일이 mp3가 아니라 mp4등의 비디오 파일인 경우는 librosa에서 지원하지 않으므로 moviepy를 이용해서 mp3로 변환 한 후에 사용\n",
    "# 파일 확장자만 바꾼다고 형식이 바뀌지는 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwzEl462Kz71",
    "outputId": "2ebd6f84-3ea3-4cda-b19c-b89016c512ae",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 오디오 파일 로드\n",
    "y1, sr1 = librosa.load(file1)\n",
    "y2, sr2 = librosa.load(file2)\n",
    "y3, sr3 = librosa.load(file3)\n",
    "\n",
    "# 기본 주파수 추정\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(y1,sr=sr1, fmin = librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "f0_2, voiced_flag_2, voiced_probs_2 = librosa.pyin(y2, sr = sr2, fmin = librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "f0_3, voiced_flag_3, voiced_probs_3 = librosa.pyin(y3, sr = sr3, fmin = librosa.note_to_hz('C2'), fmax = librosa.note_to_hz('C7'))\n",
    "\n",
    "# NaN 값을 선형 보간법으로 채우기\n",
    "f0_interpolated = pd.Series(f0).interpolate().to_numpy()\n",
    "f0_2_interpolated = pd.Series(f0_2).interpolate().to_numpy()\n",
    "f0_3_interpolated = pd.Series(f0_3).interpolate().to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FckfQQJQ7Bl"
   },
   "source": [
    "1옥타브\n",
    "C(도) 32\n",
    "D(레) 36\n",
    "E(미) 41\n",
    "F(파) 43\n",
    "G(솔) 48\n",
    "A(라) 55\n",
    "B(시) 61\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "ZgZOzNU-QO72",
    "outputId": "81fdc37c-fdf3-426c-a893-bc89698262e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 정적인 그래프 처리용 백엔드 모드\n",
    "%matplotlib inline\n",
    "\n",
    "# 시간 축 계산\n",
    "times = librosa.times_like(f0, sr=sr1)\n",
    "times_2 = librosa.times_like(f0_2, sr=sr2)\n",
    "times_3 = librosa.times_like(f0_3, sr=sr3)\n",
    "\n",
    "# 그래프로 주파수 시각화\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(times, f0_interpolated, label='Estimated F0 - File 1', color='r')\n",
    "plt.plot(times_2, f0_2_interpolated, label='Estimated F0 - File 2', color='b')\n",
    "# plt.plot(times_3, f0_3_interpolated, label='Estimated F0 - FIle 3', color = 'y')\n",
    "\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Hz')\n",
    "# plt.title('Fundamental Frequency Over Time')\n",
    "plt.ylim([librosa.note_to_hz('C2'), 650])\n",
    "\n",
    "current_time = datetime.now().strftime('%Y%m%d_%H%M%S') # 'YYYYMMDD_HHMMSS' 형식\n",
    "\n",
    "plt.savefig(f'sim_wave_{current_time}.png', dpi=300, facecolor='white', edgecolor='black',orientation='portrait', format='png', transparent=False, bbox_inches = 'tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LioZfsC4T3zv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 분석 위한 데이터 전처리\n",
    "def music_prep(music_1, music_2):\n",
    "  # 두 주파수 데이터의 최소 길이 맞추기\n",
    "  min_length = min(len(music_1), len(music_2))\n",
    "  music_1 = music_1[:min_length]\n",
    "  music_2 = music_2[:min_length]\n",
    "\n",
    "  # NaN 값이 있는 인덱스 제거\n",
    "  valid_idx = ~np.isnan(music_1) & ~np.isnan(music_2)\n",
    "  music_1_valid = music_1[valid_idx]\n",
    "  music_2_valid = music_2[valid_idx]\n",
    "  return music_1_valid, music_2_valid\n",
    "\n",
    "# 평균 유사도 계산\n",
    "def calc_similarity(music_1, music_2):\n",
    "  # 전처리\n",
    "  music_1, music_2 = music_prep(music_1, music_2)\n",
    "\n",
    "  # 두 주파수 값의 차이 계산\n",
    "  music_difference = np.abs(music_1 - music_2)\n",
    "\n",
    "  # 평균 절대 차이 계산\n",
    "  mean_difference = np.mean(music_difference)\n",
    "#   print(\"mean_difference:\", mean_difference)\n",
    "\n",
    "  # 최대 주파수 범위, 비교 기준인 music_1의 주파수 범위\n",
    "  freq_scope =  max(music_1) - min(music_1)\n",
    "#   print(\"freq:\", freq_scope)\n",
    "\n",
    "  # 평균 유사도 계산 (1-(평균 차이 / 주파수 범위))\n",
    "  similarity = (1 - (mean_difference / freq_scope)) * 100\n",
    "  similarity = round(similarity, 2)\n",
    "  print(f'The overall frequency similarity between the two audio files is approximately {similarity:.2f}%')\n",
    "  return similarity\n",
    "  \n",
    "\n",
    "\n",
    "# 가장 비슷한 부분, 가장 다른 부분 찾기\n",
    "def find_segment(music_1, music_2, sr, hop_length, time_length):\n",
    "  # 전처리\n",
    "  music_1, music_2 = music_prep(music_1, music_2)\n",
    "\n",
    "  # hop_length / sr = 한 프레임이 차지하는 시간\n",
    "  valid_duration_seconds = len(music_1) * hop_length / sr\n",
    "\n",
    "  # noticible_time_length (초) 만큼에 해당하는 프레임 갯수\n",
    "  frame_length = int(time_length / (hop_length / sr))\n",
    "\n",
    "  print(f'Duration of valid (non-NaN) data: {valid_duration_seconds:.2f} seconds')\n",
    "\n",
    "  # 두 주파수 값의 차이 계산\n",
    "  music_difference = np.abs(music_1 - music_2)\n",
    "\n",
    "  # 가장 큰 차이 값을 가지는 구간 찾기\n",
    "  max_diff = 0\n",
    "  max_index = 0\n",
    "  for i in range(len(music_difference) - frame_length +1):\n",
    "    current_diff = np.sum(music_difference[i:i+frame_length])\n",
    "    if current_diff > max_diff :\n",
    "      max_diff = current_diff\n",
    "      max_index = i\n",
    "  print(f'Maximum difference found in the frame range starting at index {max_index} with a total difference of {max_diff}')\n",
    "\n",
    "  # 가장 적은 차이 값을 가지는 구간 찾기\n",
    "  min_diff = 650 * 5\n",
    "  min_index = 0\n",
    "  for i in range(len(music_difference) - frame_length +1):\n",
    "    current_diff = np.sum(music_difference[i:i+frame_length])\n",
    "    if current_diff < min_diff :\n",
    "      min_diff = current_diff\n",
    "      min_index = i\n",
    "  print(f'Minimum difference found in the frame range starting at index {min_index} with a total difference of {min_diff}')\n",
    "\n",
    "  # 해당 구간의 시간대 계산\n",
    "  worst_time = max_index * hop_length / sr\n",
    "  best_time = min_index * hop_length / sr\n",
    "  \n",
    "  return worst_time, best_time, time_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "r_qNQagurVek"
   },
   "outputs": [],
   "source": [
    "# def play_segment(file1, file2, start_time, end_time):\n",
    "#   #오디오 파일 로드\n",
    "#   audio1 = AudioSegment.from_file(file1)\n",
    "#   audio2 = AudioSegment.from_file(file2)\n",
    "\n",
    "#   #해당 시간 구간 추출\n",
    "#   seg1 = audio1[start_time * 1000:end_time*1000] # 시간이 밀리초 단위\n",
    "#   seg2 = audio2[start_time * 1000:end_time*1000] # 시간이 밀리초 단위\n",
    "\n",
    "#   # 재생 함수 정의\n",
    "#   def play_audio_segment(segment):\n",
    "#     play(segment)\n",
    "\n",
    "#   # 각각의 오디오 세그먼트를 재생할 스레드 생성\n",
    "#   thread1 = threading.Thread(target=play_audio_segment, args = (seg1,))\n",
    "#   thread2 = threading.Thread(target=play_audio_segment, args = (seg2,))\n",
    "\n",
    "\n",
    "#   # 스레드를 시작하여 동시에 재생\n",
    "#     thread2.start()  \n",
    "#     thread1.start()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zF8QloCrB96",
    "outputId": "7435b630-4340-4c14-81a1-6c9c70abe3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall frequency similarity between the two audio files is approximately 92.49%\n",
      "Duration of valid (non-NaN) data: 58.42 seconds\n",
      "Maximum difference found in the frame range starting at index 1837 with a total difference of 14573.510770756857\n",
      "Minimum difference found in the frame range starting at index 327 with a total difference of 2309.786867422446\n"
     ]
    }
   ],
   "source": [
    "# json 파일을 현재 폴더에 상대경로로 저장\n",
    "# 파일명 : sim_result_현재시각\n",
    "# 저장경로 : 현재 경로\n",
    "\n",
    "\n",
    "similarity = calc_similarity(music_1=f0_interpolated, music_2=f0_2_interpolated) # pyin defalut hop_length : 512\n",
    "worst_time, best_time, time_length = find_segment(music_1=f0_interpolated, music_2=f0_2_interpolated, sr = sr1, hop_length= 512, time_length=5) # pyin defalut hop_length : 512\n",
    "\n",
    "\n",
    "json_object = {\n",
    "      \"id\":1,\n",
    "      \"similarity\":round(similarity, 2),\n",
    "      \"worst_time\":worst_time,\n",
    "      \"best_time\":best_time,\n",
    "      \"time_length\":time_length\n",
    "}\n",
    "\n",
    "# current_time -> pyplot이미지와 동일한 시간 변수 사용\n",
    "file_name = f'sim_result_{current_time}.json'\n",
    "file_path = f'./{file_name}'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(json_object, json_file, indent=4) # indent 4 는 가독성을 위함.\n",
    "\n",
    "# 해당 구간 동시 재생\n",
    "#play_segment(file1, file2, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QnGWDjllqXP2",
    "outputId": "ff268292-27a9-4d42-c9e5-f7ffa56654f6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mSoundFile(path)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'file1': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m anim_html, audio\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 오디오 파일 로드\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m y1, sr1 \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m y2, sr2 \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 기본 주파수 추정\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m<decorator-gen-116>:2\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m audioread\u001b[38;5;241m.\u001b[39maudio_open(path)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file1'"
     ]
    }
   ],
   "source": [
    "# 애니메이션 처리를 위해 인터랙티브 모드로 전환\n",
    "%matplotlib notebook\n",
    "\n",
    "def create_animation(y, sr, f0_interpolated, times, label, color):\n",
    "    # 그래프 설정\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, times[-1])\n",
    "    ax.set_ylim(librosa.note_to_hz('C2'), 650)\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "\n",
    "    # 오디오 전체 길이 (초 단위)\n",
    "    audio_duration = len(y) / sr\n",
    "\n",
    "    # 프레임 수 줄이기 : 10%만 사용\n",
    "    reduced_frames = times[::10]\n",
    "    reduced_f0 = f0_interpolated[::10]\n",
    "\n",
    "    # 애니메이션 프레임 설정\n",
    "    num_frames = len(reduced_frames)\n",
    "\n",
    "    # 각 프레임 간격을 오디오 재생 시간에 맞게 조정\n",
    "    interval = audio_duration / num_frames * 1000  # 밀리초 단위로 변환\n",
    "\n",
    "    # 초기화 함수\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return line,\n",
    "\n",
    "    # 업데이트 함수\n",
    "    def update(frame):\n",
    "        line.set_data(reduced_frames[:frame], reduced_f0[:frame])\n",
    "        return line,\n",
    "\n",
    "    # 라인 초기화\n",
    "    line, = ax.plot([], [], label=label, color=color)\n",
    "\n",
    "    # 애니메이션 생성\n",
    "    ani = animation.FuncAnimation(fig, update, frames=num_frames, init_func=init, blit=False, interval=interval, repeat=False)\n",
    "\n",
    "    anim_html = HTML(ani.to_jshtml())\n",
    "    audio = Audio(y, rate=sr)\n",
    "\n",
    "    return anim_html, audio\n",
    "\n",
    "# 오디오 파일 로드\n",
    "y1, sr1 = librosa.load('file1')\n",
    "y2, sr2 = librosa.load('file2')\n",
    "\n",
    "# 기본 주파수 추정\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(y1, sr=sr1, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "f0_2, voiced_flag_2, voiced_probs_2 = librosa.pyin(y2, sr=sr2, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "\n",
    "# NaN 값을 선형 보간법으로 채우기\n",
    "f0_interpolated = pd.Series(f0).interpolate().to_numpy()\n",
    "f0_2_interpolated = pd.Series(f0_2).interpolate().to_numpy()\n",
    "\n",
    "# 시간 축 계산\n",
    "times = librosa.times_like(f0, sr=sr1)\n",
    "times_2 = librosa.times_like(f0_2, sr=sr2)\n",
    "\n",
    "# 애니메이션 및 오디오 생성\n",
    "anim_html_1, audio_1 = create_animation(y1, sr1, f0_interpolated, times, 'Estimated F0 - File 1', 'r')\n",
    "anim_html_2, audio_2 = create_animation(y2, sr2, f0_2_interpolated, times_2, 'Estimated F0 - File 2', 'b')\n",
    "\n",
    "# 두 애니메이션과 오디오 플레이어를 표시\n",
    "display(anim_html_1, audio_1)\n",
    "display(anim_html_2, audio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "SshAk0uXOiXY",
    "outputId": "21f63324-5a61-4277-ba81-2e6ce1c25f83"
   },
   "outputs": [],
   "source": [
    "# 스펙트로그램 표현\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y1)), ref=np.max)\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "ax.set(title = 'pYIN fundamental frequency estimation')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "ax.plot(times, f0, label='f0', color='cyan', linewidth=3)\n",
    "ax.legend(loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
